# -*- coding: utf-8 -*-
"""separar_basura.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OrI8IoyXNV-ACikQ7OcClNlWwwBS1w59
"""

# Preparar entorno
!pip install tensorflow matplotlib

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import os

#Preprocesamiento
ruta_dataset = '/content/drive/MyDrive/Noveno/Inteligecia Artificial/proyecto/imagenes'

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = datagen.flow_from_directory(
    ruta_dataset,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    ruta_dataset,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# 5. Crear y compilar modelo
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

#Entrenamiento del modelo
history = model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)

# 7. Guardar modelo y clases
import json
# Cambiar la extensi√≥n del archivo a .h5 para compatibilidad con Keras 3
modelo_path = '/content/modelo.h5'
# Eliminar el argumento save_format="tf" ya que est√° obsoleto en Keras 3
model.save(modelo_path)


clases = list(train_generator.class_indices.keys())
clases_path = '/content/clases.json'
with open(clases_path, "w") as f:
    json.dump(clases, f)


clases = list(train_generator.class_indices.keys())
clases_path = '/content/drive/MyDrive/Noveno/Inteligecia Artificial/proyecto/clases.json'
with open(clases_path, "w") as f:
    json.dump(clases, f)

#Evaluar modelo
plt.plot(history.history['accuracy'], label='Precisi√≥n entrenamiento')
plt.plot(history.history['val_accuracy'], label='Precisi√≥n validaci√≥n')
plt.legend()
plt.title('Precisi√≥n durante el entrenamiento')
plt.show()

#Perdidas
plt.plot(history.history['loss'], label='P√©rdida entrenamiento')
plt.plot(history.history['val_loss'], label='P√©rdida validaci√≥n')
plt.legend()
plt.title('P√©rdida durante el entrenamiento')
plt.show()

#Clases aprendidas por el modelo
CLASES = list(train_generator.class_indices.keys())
print(CLASES)

import json

clases = list(train_generator.class_indices.keys())
with open("clases.json", "w") as f:
    json.dump(clases, f)

#Verificar modelo
train_generator = datagen.flow_from_directory(
    ruta_dataset, # Cambiar 'ruta' por 'ruta_dataset'
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)
CLASES = list(train_generator.class_indices.keys())
print(CLASES)

import tensorflow as tf
import numpy as np
from PIL import Image
import json

# Cargar clases desde JSON
with open('/content/clases.json', 'r') as f:
    CLASES = json.load(f)

print("Clases cargadas:", CLASES)
print("N√∫mero de clases:", len(CLASES))

# Cargar el modelo
modelo = tf.keras.models.load_model('/content/drive/MyDrive/Noveno/Inteligecia Artificial/proyecto/modelo/modelo.h5')

# Ruta de la imagen
ruta_imagen = '/content/imagen_temporal.jpg'

# Add this before the cell that loads the image
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Cargar y preprocesar la imagen
imagen = Image.open(ruta_imagen).convert('RGB')
imagen = imagen.resize((150, 150))
arr = np.array(imagen) / 255.0
arr = np.expand_dims(arr, axis=0)

# Realizar la predicci√≥n
pred = modelo.predict(arr)
indice = np.argmax(pred)
confianza = np.max(pred) * 100

# Mostrar resultado
if indice < len(CLASES):
    print(f"‚úÖ Predicci√≥n: {CLASES[indice]}")
    print(f"üîç Confianza: {confianza:.2f}%")
else:
    print("‚ö†Ô∏è Error: √≠ndice fuera del rango de clases")

# 8. Cargar modelo y clases para predicci√≥n
with open(clases_path, 'r') as f:
    CLASES = json.load(f)

modelo = tf.keras.models.load_model(modelo_path)

# 9. Funci√≥n para predecir y mostrar resultados en un cuadro de texto
from IPython.display import display, clear_output
import ipywidgets as widgets
from PIL import Image
import numpy as np

# Cuadro de texto donde se mostrar√° la predicci√≥n
resultado_texto = widgets.Textarea(
    value='',
    placeholder='Aqu√≠ aparecer√° la predicci√≥n',
    description='Resultado:',
    layout=widgets.Layout(width='100%', height='100px'),
    disabled=True
)

# Funci√≥n de predicci√≥n
def predecir_imagen_ui(ruta_imagen):
    try:
        imagen = Image.open(ruta_imagen).convert('RGB')
        imagen_resized = imagen.resize((150, 150))
        arr = np.array(imagen_resized) / 255.0
        arr = np.expand_dims(arr, axis=0)

        pred = modelo.predict(arr)
        indice = np.argmax(pred)
        confianza = np.max(pred) * 100

        resultado = f"‚úÖ Predicci√≥n: {CLASES[indice]}\nüîç Confianza: {confianza:.2f}%"
        resultado_texto.value = resultado

        clear_output()
        display(widgets.VBox([file_picker, resultado_texto, output]))

    except Exception as e:
        resultado_texto.value = f"‚ùå Error al procesar la imagen: {e}"

# 10. Crear widget para subir archivo
file_picker = widgets.FileUpload(
    accept='image/*',
    multiple=False,
    description='üì∑ Subir imagen',
    style={'button_color': '#2d9cdb'}
)

output = widgets.Output()

def on_file_upload(change):
    with output:
        output.clear_output()
        if len(file_picker.value) > 0:
            key = list(file_picker.value.keys())[0]
            content = file_picker.value[key]['content']
            ruta_temp = '/content/imagen_temporal.jpg'
            with open(ruta_temp, 'wb') as f:
                f.write(content)
            predecir_imagen_ui(ruta_temp)

file_picker.observe(on_file_upload, names='value')

# Mostrar la interfaz
display(widgets.VBox([file_picker, resultado_texto, output]))